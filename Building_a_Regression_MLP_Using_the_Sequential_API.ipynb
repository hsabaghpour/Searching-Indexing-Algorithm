{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJFcQnlmagDfNIqSex65D7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsabaghpour/Searching-Indexing-Algorithm/blob/main/Building_a_Regression_MLP_Using_the_Sequential_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're using Keras' Sequential API to create a regression model for the California housing problem. This model has 3 hidden layers, each with 50 neurons. The main differences for regression are:\n",
        "\n",
        "The output layer has 1 neuron (we're predicting a single value).\n",
        "No activation function is used in the output layer.\n",
        "The loss function is mean squared error (MSE).\n",
        "We measure performance with root mean squared error (RMSE).\n",
        "We employ the Adam optimizer.\n",
        "Instead of a Flatten layer, we use a Normalization layer as the first layer to preprocess the data like Scikit-Learn's StandardScaler. Make sure to adapt it to the training data before fitting the model."
      ],
      "metadata": {
        "id": "yUBGO5T3YKB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
        "tf.random.set_seed(42)\n",
        "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
        "model = tf.keras.Sequential([\n",
        "    norm_layer,\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
        "norm_layer.adapt(X_train)\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqT9aaUfYNZT",
        "outputId": "cccc4f72-72a5-40bd-dca4-c1d90897e9a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 1.1603 - root_mean_squared_error: 1.0772 - val_loss: 0.4385 - val_root_mean_squared_error: 0.6622\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4146 - root_mean_squared_error: 0.6439 - val_loss: 0.3927 - val_root_mean_squared_error: 0.6267\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3811 - root_mean_squared_error: 0.6173 - val_loss: 0.3668 - val_root_mean_squared_error: 0.6057\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3596 - root_mean_squared_error: 0.5996 - val_loss: 0.3522 - val_root_mean_squared_error: 0.5935\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3472 - root_mean_squared_error: 0.5892 - val_loss: 0.3454 - val_root_mean_squared_error: 0.5877\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3343 - root_mean_squared_error: 0.5782 - val_loss: 0.3294 - val_root_mean_squared_error: 0.5739\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3415 - root_mean_squared_error: 0.5844 - val_loss: 0.3281 - val_root_mean_squared_error: 0.5728\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3147 - root_mean_squared_error: 0.5610 - val_loss: 0.3126 - val_root_mean_squared_error: 0.5591\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3121 - root_mean_squared_error: 0.5586 - val_loss: 0.3161 - val_root_mean_squared_error: 0.5622\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3116 - root_mean_squared_error: 0.5582 - val_loss: 0.3142 - val_root_mean_squared_error: 0.5606\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3193 - root_mean_squared_error: 0.5651 - val_loss: 0.3085 - val_root_mean_squared_error: 0.5554\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2969 - root_mean_squared_error: 0.5449 - val_loss: 0.3016 - val_root_mean_squared_error: 0.5492\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2996 - root_mean_squared_error: 0.5474 - val_loss: 0.3020 - val_root_mean_squared_error: 0.5496\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2919 - root_mean_squared_error: 0.5402 - val_loss: 0.3088 - val_root_mean_squared_error: 0.5557\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3113 - root_mean_squared_error: 0.5580 - val_loss: 0.3084 - val_root_mean_squared_error: 0.5553\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2977 - root_mean_squared_error: 0.5456 - val_loss: 0.3061 - val_root_mean_squared_error: 0.5533\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.2858 - root_mean_squared_error: 0.5346 - val_loss: 0.2958 - val_root_mean_squared_error: 0.5439\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2847 - root_mean_squared_error: 0.5336 - val_loss: 0.2968 - val_root_mean_squared_error: 0.5448\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2809 - root_mean_squared_error: 0.5300 - val_loss: 0.2960 - val_root_mean_squared_error: 0.5441\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2797 - root_mean_squared_error: 0.5288 - val_loss: 0.3104 - val_root_mean_squared_error: 0.5571\n",
            "162/162 [==============================] - 0s 2ms/step - loss: 0.2925 - root_mean_squared_error: 0.5408\n",
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code does the following:\n",
        "\n",
        "Loads the California housing dataset and prepares the data for training and testing.\n",
        "\n",
        "Creates a neural network model with normalization and multiple hidden layers for regression.\n",
        "\n",
        "Trains the model on the training data for 20 epochs, monitoring performance on validation data.\n",
        "\n",
        "Evaluates the model's performance on the test data, calculating both mean squared error (MSE) and root mean squared error (RMSE).\n",
        "\n",
        "Makes predictions with the trained model on new data.\n",
        "\n",
        "In essence, it builds and trains a neural network for predicting house prices in California, providing evaluation metrics and the ability to make predictions on new data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W-tcpH5Ub0bp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Iq6I32vAb-p5"
      }
    }
  ]
}